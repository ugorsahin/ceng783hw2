{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a ConvNet!\n",
    "We now have a generic solver and a bunch of modularized layers. It's time to put it all together, and train a ConvNet to recognize the classes in CIFAR-10. In this notebook we will walk you through training a simple two-layer ConvNet and then set you free to build the best net that you can to perform well on CIFAR-10.\n",
    "\n",
    "Open up the file `cs231n/classifiers/convnet.py`; you will see that the `two_layer_convnet` function computes the loss and gradients for a two-layer ConvNet. Note that this function uses the \"sandwich\" layers defined in `cs231n/layer_utils.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual, a bit of setup\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifier_trainer import ClassifierTrainer\n",
    "from cs231n.gradient_check import eval_numerical_gradient\n",
    "from cs231n.classifiers.convnet import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-18, np.abs(x) + np.abs(y))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (19000, 3, 32, 32)\n",
      "Train labels shape:  (19000,)\n",
      "Validation data shape:  (1000, 3, 32, 32)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 32, 32, 3)\n",
      "Test labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "from cs231n.data_utils import load_CIFAR10\n",
    "# Modify load_CIFAR10 and the following function to load less data if you have memory issues.\n",
    "# Load batches 1, 2 and 3; and call the function as follows:\n",
    "#def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "def get_CIFAR10_data(num_training=19000, num_validation=1000, num_test=1000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "        \n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    \n",
    "    # Transpose so that channels come first\n",
    "    X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
    "    X_val = X_val.transpose(0, 3, 1, 2).copy()\n",
    "    x_test = X_test.transpose(0, 3, 1, 2).copy()\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print ('Train data shape: ', X_train.shape)\n",
    "print ('Train labels shape: ', y_train.shape)\n",
    "print ('Validation data shape: ', X_val.shape)\n",
    "print ('Validation labels shape: ', y_val.shape)\n",
    "print ('Test data shape: ', X_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check loss\n",
    "After you build a new network, one of the first things you should do is sanity check the loss. When we use the softmax loss, we expect the loss for random weights (and no regularization) to be about `log(C)` for `C` classes. When we add regularization this should go up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check loss (no regularization):  2.3025850925986258\n",
      "Sanity check loss (with regularization):  2.9601835650655985\n"
     ]
    }
   ],
   "source": [
    "from cs231n.classifiers.convnet import *\n",
    "model = init_unet_classifier()\n",
    "\n",
    "X = np.random.randn(100, 3, 32, 32)\n",
    "y = np.random.randint(10, size=100)\n",
    "\n",
    "loss, _ = unet_classifier(X, model, y, reg=0)\n",
    "\n",
    "# Sanity check: Loss should be about log(10) = 2.3026\n",
    "print ('Sanity check loss (no regularization): ', loss)\n",
    "\n",
    "# Sanity check: Loss should go up when you add regularization\n",
    "loss, _ = unet_classifier(X, model, y, reg=1)\n",
    "print ('Sanity check loss (with regularization): ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient check\n",
    "After the loss looks reasonable, you should always use numeric gradient checking to make sure that your backward pass is correct. When you use numeric gradient checking you should use a small amount of artifical data and a small number of neurons at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convW0 max relative error: 1.000000e+00\n",
      "convW1 max relative error: 1.000000e+00\n",
      "convW2 max relative error: 1.000000e+00\n",
      "convb0 max relative error: 1.978632e-01\n",
      "convb1 max relative error: 1.682680e-02\n",
      "convb2 max relative error: 1.000000e+00\n",
      "fcW0 max relative error: 1.000000e+00\n",
      "fcb0 max relative error: 7.367199e-05\n",
      "outW max relative error: 1.000000e+00\n",
      "outb max relative error: 2.234765e-07\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 2\n",
    "input_shape = (3, 16, 16)\n",
    "reg = 0.0\n",
    "num_classes = 10\n",
    "X = np.random.randn(num_inputs, *input_shape)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "model = init_unet_classifier(num_filters=[2,4,6], filter_size=5, input_shape=input_shape)\n",
    "loss, grads = unet_classifier(X, model, y)\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: unet_classifier(X, model, y)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model[param_name], verbose=False, h=1e-6)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print ('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit small data\n",
    "A nice trick is to train your model with just a few training samples. You should be able to overfit small datasets, which will result in very high training accuracy and comparatively low validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting iteration  0\n",
      "Finished epoch 0 / 10: cost 2.302854, train: 0.100000, val 0.104000, lr 1.000000e-03\n",
      "\n",
      "Finished epoch 1 / 10: cost 2.732344, train: 0.160000, val 0.115000, lr 9.500000e-04\n",
      "starting iteration  10\n",
      "Finished epoch 2 / 10: cost 2.028680, train: 0.120000, val 0.106000, lr 9.025000e-04\n",
      "starting iteration  20\n",
      "Finished epoch 3 / 10: cost 2.158528, train: 0.220000, val 0.121000, lr 8.573750e-04\n",
      "starting iteration  30\n",
      "Finished epoch 4 / 10: cost 2.788779, train: 0.200000, val 0.121000, lr 8.145062e-04\n",
      "starting iteration  40\n",
      "Finished epoch 5 / 10: cost 2.277648, train: 0.240000, val 0.136000, lr 7.737809e-04\n",
      "starting iteration  50\n",
      "Finished epoch 6 / 10: cost 2.124102, train: 0.240000, val 0.129000, lr 7.350919e-04\n",
      "starting iteration  60\n",
      "Finished epoch 7 / 10: cost 2.010990, train: 0.220000, val 0.129000, lr 6.983373e-04\n",
      "starting iteration  70\n",
      "Finished epoch 8 / 10: cost 1.952675, train: 0.300000, val 0.146000, lr 6.634204e-04\n",
      "starting iteration  80\n",
      "Finished epoch 9 / 10: cost 1.996290, train: 0.380000, val 0.140000, lr 6.302494e-04\n",
      "starting iteration  90\n",
      "Finished epoch 10 / 10: cost 2.153970, train: 0.420000, val 0.145000, lr 5.987369e-04\n",
      "finished optimization. best validation accuracy: 0.146000\n"
     ]
    }
   ],
   "source": [
    "# Use a two-layer ConvNet to overfit 50 training examples.\n",
    "\n",
    "model = init_unet_classifier(num_filters=[8,16])\n",
    "trainer = ClassifierTrainer()\n",
    "best_model, loss_history, train_acc_history, val_acc_history = trainer.train(\n",
    "          X_train[:50], y_train[:50], X_val, y_val, model, unet_classifier,\n",
    "          reg=0.001, update=\"rmsprop\", momentum=0.9, learning_rate=0.001, batch_size=5, num_epochs=10,\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the loss, training accuracy, and validation accuracy should show clear overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(train_acc_history)\n",
    "plt.plot(val_acc_history)\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the net\n",
    "Once the above works, training the net is the next thing to try. You can set the `acc_frequency` parameter to change the frequency at which the training and validation set accuracies are tested. If your parameters are set properly, you should see the training and validation accuracy start to improve within a hundred iterations, and you should be able to train a reasonable model with just one epoch.\n",
    "\n",
    "Using the parameters below you should be able to get around 50% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting iteration  0\n",
      "Finished epoch 0 / 4: cost 0.593840, train: 0.760000, val 0.610000, lr 1.000000e-06\n",
      "starting iteration  50\n",
      "Finished epoch 0 / 4: cost 0.734365, train: 0.777000, val 0.609000, lr 1.000000e-06\n",
      "starting iteration  100\n",
      "Finished epoch 0 / 4: cost 0.566677, train: 0.783000, val 0.607000, lr 1.000000e-06\n",
      "starting iteration  150\n",
      "Finished epoch 0 / 4: cost 0.927831, train: 0.765000, val 0.607000, lr 1.000000e-06\n",
      "starting iteration  200\n",
      "Finished epoch 0 / 4: cost 1.080134, train: 0.791000, val 0.604000, lr 1.000000e-06\n",
      "starting iteration  250\n",
      "Finished epoch 0 / 4: cost 0.885584, train: 0.751000, val 0.604000, lr 1.000000e-06\n",
      "starting iteration  300\n",
      "Finished epoch 0 / 4: cost 0.595857, train: 0.753000, val 0.604000, lr 1.000000e-06\n",
      "starting iteration  350\n",
      "Finished epoch 0 / 4: cost 0.761939, train: 0.763000, val 0.605000, lr 1.000000e-06\n",
      "starting iteration  400\n",
      "Finished epoch 0 / 4: cost 0.793510, train: 0.762000, val 0.606000, lr 1.000000e-06\n",
      "starting iteration  450\n",
      "Finished epoch 0 / 4: cost 0.824454, train: 0.763000, val 0.604000, lr 1.000000e-06\n",
      "starting iteration  500\n",
      "Finished epoch 0 / 4: cost 0.666395, train: 0.763000, val 0.603000, lr 1.000000e-06\n",
      "starting iteration  550\n",
      "Finished epoch 0 / 4: cost 0.553789, train: 0.782000, val 0.602000, lr 1.000000e-06\n",
      "starting iteration  590\n",
      "Finished epoch 1 / 4: cost 0.635949, train: 0.788000, val 0.602000, lr 9.500000e-07\n",
      "starting iteration  600\n",
      "Finished epoch 1 / 4: cost 0.756243, train: 0.752000, val 0.602000, lr 9.500000e-07\n",
      "starting iteration  650\n",
      "Finished epoch 1 / 4: cost 0.836040, train: 0.779000, val 0.603000, lr 9.500000e-07\n",
      "starting iteration  700\n",
      "Finished epoch 1 / 4: cost 0.553233, train: 0.758000, val 0.603000, lr 9.500000e-07\n",
      "starting iteration  750\n",
      "Finished epoch 1 / 4: cost 0.637424, train: 0.777000, val 0.603000, lr 9.500000e-07\n",
      "starting iteration  800\n",
      "Finished epoch 1 / 4: cost 0.445756, train: 0.809000, val 0.603000, lr 9.500000e-07\n",
      "starting iteration  850\n",
      "Finished epoch 1 / 4: cost 0.652430, train: 0.770000, val 0.600000, lr 9.500000e-07\n",
      "starting iteration  900\n",
      "Finished epoch 1 / 4: cost 0.651540, train: 0.768000, val 0.601000, lr 9.500000e-07\n",
      "starting iteration  950\n",
      "Finished epoch 1 / 4: cost 0.770231, train: 0.787000, val 0.600000, lr 9.500000e-07\n",
      "starting iteration  1000\n",
      "Finished epoch 1 / 4: cost 0.545542, train: 0.765000, val 0.600000, lr 9.500000e-07\n",
      "starting iteration  1050\n",
      "Finished epoch 1 / 4: cost 0.791868, train: 0.761000, val 0.601000, lr 9.500000e-07\n",
      "starting iteration  1100\n",
      "Finished epoch 1 / 4: cost 0.507990, train: 0.792000, val 0.601000, lr 9.500000e-07\n",
      "starting iteration  1150\n",
      "Finished epoch 1 / 4: cost 0.829787, train: 0.769000, val 0.604000, lr 9.500000e-07\n",
      "starting iteration  1180\n",
      "Finished epoch 2 / 4: cost 0.775445, train: 0.797000, val 0.602000, lr 9.025000e-07\n",
      "starting iteration  1200\n",
      "Finished epoch 2 / 4: cost 1.005830, train: 0.770000, val 0.603000, lr 9.025000e-07\n",
      "starting iteration  1250\n",
      "Finished epoch 2 / 4: cost 0.732112, train: 0.768000, val 0.602000, lr 9.025000e-07\n",
      "starting iteration  1300\n",
      "Finished epoch 2 / 4: cost 0.646625, train: 0.766000, val 0.604000, lr 9.025000e-07\n",
      "starting iteration  1350\n",
      "Finished epoch 2 / 4: cost 0.753648, train: 0.777000, val 0.602000, lr 9.025000e-07\n",
      "starting iteration  1400\n",
      "Finished epoch 2 / 4: cost 0.772245, train: 0.770000, val 0.604000, lr 9.025000e-07\n",
      "starting iteration  1450\n",
      "Finished epoch 2 / 4: cost 0.689280, train: 0.768000, val 0.602000, lr 9.025000e-07\n",
      "starting iteration  1500\n",
      "Finished epoch 2 / 4: cost 0.724887, train: 0.786000, val 0.603000, lr 9.025000e-07\n",
      "starting iteration  1550\n",
      "Finished epoch 2 / 4: cost 0.381234, train: 0.776000, val 0.601000, lr 9.025000e-07\n",
      "starting iteration  1600\n",
      "Finished epoch 2 / 4: cost 0.816675, train: 0.789000, val 0.601000, lr 9.025000e-07\n",
      "starting iteration  1650\n",
      "Finished epoch 2 / 4: cost 0.822736, train: 0.784000, val 0.602000, lr 9.025000e-07\n",
      "starting iteration  1700\n",
      "Finished epoch 2 / 4: cost 0.580727, train: 0.758000, val 0.603000, lr 9.025000e-07\n",
      "starting iteration  1750\n",
      "Finished epoch 2 / 4: cost 0.499054, train: 0.749000, val 0.601000, lr 9.025000e-07\n",
      "starting iteration  1770\n",
      "Finished epoch 3 / 4: cost 0.956949, train: 0.759000, val 0.603000, lr 8.573750e-07\n",
      "starting iteration  1800\n",
      "Finished epoch 3 / 4: cost 0.572045, train: 0.757000, val 0.602000, lr 8.573750e-07\n",
      "starting iteration  1850\n",
      "Finished epoch 3 / 4: cost 0.703805, train: 0.772000, val 0.602000, lr 8.573750e-07\n",
      "starting iteration  1900\n",
      "Finished epoch 3 / 4: cost 0.653590, train: 0.768000, val 0.600000, lr 8.573750e-07\n",
      "starting iteration  1950\n",
      "Finished epoch 3 / 4: cost 0.543242, train: 0.760000, val 0.601000, lr 8.573750e-07\n",
      "starting iteration  2000\n",
      "Finished epoch 3 / 4: cost 0.553973, train: 0.758000, val 0.602000, lr 8.573750e-07\n",
      "starting iteration  2050\n",
      "Finished epoch 3 / 4: cost 0.663021, train: 0.761000, val 0.601000, lr 8.573750e-07\n",
      "starting iteration  2100\n",
      "Finished epoch 3 / 4: cost 0.577768, train: 0.768000, val 0.601000, lr 8.573750e-07\n",
      "starting iteration  2150\n",
      "Finished epoch 3 / 4: cost 1.052705, train: 0.772000, val 0.599000, lr 8.573750e-07\n",
      "starting iteration  2200\n",
      "Finished epoch 3 / 4: cost 0.848295, train: 0.767000, val 0.600000, lr 8.573750e-07\n",
      "starting iteration  2250\n",
      "Finished epoch 3 / 4: cost 0.850571, train: 0.785000, val 0.601000, lr 8.573750e-07\n",
      "starting iteration  2300\n",
      "Finished epoch 3 / 4: cost 0.722172, train: 0.791000, val 0.605000, lr 8.573750e-07\n",
      "starting iteration  2350\n",
      "Finished epoch 3 / 4: cost 0.471767, train: 0.777000, val 0.605000, lr 8.573750e-07\n",
      "starting iteration  2370\n",
      "Finished epoch 4 / 4: cost 0.788891, train: 0.774000, val 0.604000, lr 8.145062e-07\n",
      "finished optimization. best validation accuracy: 0.610000\n"
     ]
    }
   ],
   "source": [
    "#model = init_unet_classifier(num_filters=[16,32,64])\n",
    "trainer = ClassifierTrainer()\n",
    "best_model, loss_history, train_acc_history, val_acc_history = trainer.train(\n",
    "          X_train, y_train, X_val, y_val, best_model, unet_classifier,\n",
    "          reg=0.001, update=\"adam\", learning_rate=0.000001, batch_size=128, num_epochs=4,\n",
    "          acc_frequency=50, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize weights\n",
    "We can visualize the convolutional weights from the first layer. If everything worked properly, these will usually be edges and blobs of various colors and orientations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 23, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3432ee4cf8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cs231n.vis_utils import visualize_grid\n",
    "grid = visualize_grid(best_model['convW0'].transpose(0, 2, 3, 1))\n",
    "print(grid.shape)\n",
    "plt.imshow(grid.astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment!\n",
    "Experiment and try to get the best performance that you can on CIFAR-10 using a ConvNet. Here are some ideas to get you started:\n",
    "\n",
    "### Things you should try:\n",
    "- Filter size: Above we used 7x7; this makes pretty pictures but smaller filters may be more efficient\n",
    "- Number of filters: Above we used 32 filters. Do more or fewer do better?\n",
    "- Network depth: The network above has two layers of trainable parameters. Can you do better with a deeper network? You can implement alternative architectures in the file `cs231n/classifiers/convnet.py`. Some good architectures to try include:\n",
    "    - [conv-relu-pool]xN - conv - relu - [affine]xM - [softmax or SVM]\n",
    "    - [conv-relu-pool]XN - [affine]XM - [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN - [affine]xM - [softmax or SVM]\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and regularization strength. When doing this there are a couple important things to keep in mind:\n",
    "\n",
    "- If the parameters are working well, you should see improvement within a few hundred iterations\n",
    "- Remember the course-to-fine approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n",
    "- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
    "\n",
    "### Going above and beyond\n",
    "If you are feeling adventurous there are many other features you can implement to try and improve your performance. You are **not required** to implement any of these; however they would be good things to try for extra credit.\n",
    "\n",
    "- Alternative update steps: For the assignment we implemented SGD+momentum and RMSprop; you could try alternatives like AdaGrad or AdaDelta.\n",
    "- Other forms of regularization such as L1 or Dropout\n",
    "- Alternative activation functions such as leaky ReLU or maxout\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "\n",
    "### What we expect\n",
    "At the very least, you should be able to train a ConvNet that gets at least 65% accuracy on the validation set. This is just a lower bound - if you are careful it should be possible to get accuracies much higher than that! Extra credit points will be awarded for particularly high-scoring models or unique approaches.\n",
    "\n",
    "You should use the space below to experiment and train your network. The final cell in this notebook should contain the training, validation, and test set accuracies for your final trained network. In this notebook you should also write an explanation of what you did, any additional features that you implemented, and any visualizations or graphs that you make in the process of training and evaluating your network.\n",
    "\n",
    "Have fun and happy training!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I overwrite the above cell in order to train. The best value i have got so far is %61. I tried double convolution with leaky relu as activation but failed due to implementation. I believe i should have built a more block based structure since things get quite messy when i tried to calculate all grads and updates manually. I named the classifier as unet because i also tried u-net architecture but that doesn't work in terms of implementation again. I failed on deconvolution with upsampling side. I believe a u-net model with depth of three could solve cifar quiet better than the current results i have."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
